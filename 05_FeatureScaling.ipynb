{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/fe/6b/db949ed5ac367987b1f250f070f340b7715d22f0c9c965bdf07de6ca75a3/scikit_learn-1.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\user\\miniconda3\\envs\\python_eda\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\miniconda3\\envs\\python_eda\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp312-cp312-win_amd64.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.1 MB 1.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/9.1 MB 1.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/9.1 MB 2.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/9.1 MB 2.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.1 MB 2.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/9.1 MB 1.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.8/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.2/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.4/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.4/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.5/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.5/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.7/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.8/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.9/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.0/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.1/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.2/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.3/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.4/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.5/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.5/9.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.7/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.8/9.1 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.9/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.9/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.0/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.0/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.1/9.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.1/9.1 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.2/9.1 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.3/9.1 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.4/9.1 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.4/9.1 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.5/9.1 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.6/9.1 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.7/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.8/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.9/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.0/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.1/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.2/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.2/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.3/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.3/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.5/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.6/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.6/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.7/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.8/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.9/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.1/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.3/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.4/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.5/9.1 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.7/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.7/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.9/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.0/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.1/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.2/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.3/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.5/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.6/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.7/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.9/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.1/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.1/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.2/9.1 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.3/9.1 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.8/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.1/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.5/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 1.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value\n",
      "0     10\n",
      "1     20\n",
      "2     30\n",
      "3     40\n",
      "4     50\n",
      "   Value  Scaled_Value\n",
      "0     10          0.00\n",
      "1     20          0.25\n",
      "2     30          0.50\n",
      "3     40          0.75\n",
      "4     50          1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Sample data\n",
    "data={'Value':[10,20,30,40,50]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df.head())\n",
    "# Min-Max Scaling\n",
    "scaler=MinMaxScaler()\n",
    "df['Scaled_Value']=scaler.fit_transform(df[['Value']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standard Scalar or Z score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value\n",
      "0     10\n",
      "1     20\n",
      "2     30\n",
      "3     40\n",
      "4     50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Sample data\n",
    "data={'Value':[10,20,30,40,50]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Scaled_Value\n",
      "0     10     -1.414214\n",
      "1     20     -0.707107\n",
      "2     30      0.000000\n",
      "3     40      0.707107\n",
      "4     50      1.414214\n"
     ]
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "df['Scaled_Value']=scaler.fit_transform(df[['Value']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robust Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value\n",
      "0     10\n",
      "1     20\n",
      "2     30\n",
      "3     40\n",
      "4     50\n",
      "   Value  Scaled_Value\n",
      "0     10          -1.0\n",
      "1     20          -0.5\n",
      "2     30           0.0\n",
      "3     40           0.5\n",
      "4     50           1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# Sample data\n",
    "data={'Value':[10,20,30,40,50]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df.head())\n",
    "# Robust Scaling\n",
    "scaler=RobustScaler()\n",
    "df['Scaled_Value']=scaler.fit_transform(df[['Value']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logrithmic Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>log_value</th>\n",
       "      <th>log_value10</th>\n",
       "      <th>log_value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.287712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>4.301030</td>\n",
       "      <td>14.287712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>10.308953</td>\n",
       "      <td>4.477121</td>\n",
       "      <td>14.872675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>11.512925</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.609640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>10.819778</td>\n",
       "      <td>4.698970</td>\n",
       "      <td>15.609640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Value  log_value  log_value10  log_value2\n",
       "0   10000   9.210340     4.000000   13.287712\n",
       "1   20000   9.903488     4.301030   14.287712\n",
       "2   30000  10.308953     4.477121   14.872675\n",
       "3  100000  11.512925     5.000000   16.609640\n",
       "4   50000  10.819778     4.698970   15.609640"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# random data with outliers\n",
    "data={'Value':[10000,20000,30000,100000,50000]}\n",
    "df=pd.DataFrame(data)\n",
    "# Log Transform\n",
    "df['log_value'] = np.log(df['Value'])\n",
    "df['log_value10'] = np.log10(df['Value'])\n",
    "df['log_value2'] = np.log2(df['Value'])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color\n",
      "0    Red\n",
      "1  Green\n",
      "2   Blue\n",
      "3    Red\n",
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1       False         True      False\n",
      "2        True        False      False\n",
      "3       False        False       True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Sample Data\n",
    "data={'Color':['Red','Green','Blue','Red']}\n",
    "df=pd.DataFrame(data)\n",
    "print (df)\n",
    "# One-Hot Encoding\n",
    "encoded_data=pd.get_dummies(df,columns=['Color'])\n",
    "print (encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Animal  Animal_encoded\n",
      "0    Dog               2\n",
      "1    Cat               1\n",
      "2  Mouse               3\n",
      "3   Bird               0\n",
      "4    Dog               2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# sample Data\n",
    "data={'Animal':['Dog','Cat','Mouse','Bird','Dog']}\n",
    "df=pd.DataFrame(data)\n",
    "# Label Encoding\n",
    "label_encoder=LabelEncoder()\n",
    "df[\"Animal_encoded\"]=label_encoder.fit_transform(df['Animal'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Size  Size_encoded\n",
      "0   Small           0.0\n",
      "1  Medium           1.0\n",
      "2   Large           2.0\n",
      "3  Medium           1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# sample Data\n",
    "data={'Size':['Small','Medium','Large','Medium']}\n",
    "df=pd.DataFrame(data)\n",
    "# Label Encoding\n",
    "ordinal_encoder=OrdinalEncoder(categories=[['Small','Medium','Large']])\n",
    "df[\"Size_encoded\"]=ordinal_encoder.fit_transform(df[['Size']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
